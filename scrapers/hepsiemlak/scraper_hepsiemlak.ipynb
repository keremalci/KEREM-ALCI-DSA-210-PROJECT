{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5fabb3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import asyncio\n",
    "import json\n",
    "import random\n",
    "from datetime import datetime\n",
    "from playwright.async_api import async_playwright\n",
    "from geopy.distance import geodesic\n",
    "import pandas as pd\n",
    "\n",
    "# Constants\n",
    "KURTKOY_METRO_COORDS = (40.909444, 29.296111)\n",
    "SABANCI_UNIV_COORDS = (40.890547, 29.378386)\n",
    "BUS_STATION_COORDS = (40.911000, 29.300000)\n",
    "\n",
    "BASE_URL = \"https://www.hepsiemlak.com/tr/pendik-kurtkoy-kiralik\"\n",
    "\n",
    "async def extract_listing_details(page, url):\n",
    "    print(f\"Scraping: {url}\")\n",
    "    try:\n",
    "        await page.goto(url, timeout=600000)\n",
    "        await page.wait_for_load_state(\"domcontentloaded\")\n",
    "        await asyncio.sleep(random.uniform(1, 3))\n",
    "\n",
    "        details = {}\n",
    "        details[\"Listing URL\"] = url\n",
    "        details[\"Collection Date\"] = datetime.now().strftime(\"%Y-%m-%d\")\n",
    "\n",
    "        # Extract from __NUXT__\n",
    "        try:\n",
    "            nuxt_data = await page.evaluate('() => window.__NUXT__')\n",
    "            if nuxt_data:\n",
    "                # The structure might vary, but usually it's in data or state\n",
    "                # Based on inspection: nuxt.data[0].list[0] or similar\n",
    "                # We will try to find the listing object recursively or by checking common keys\n",
    "                \n",
    "                listing_data = None\n",
    "                \n",
    "                # Check if we are on a detail page, the data might be in a different place\n",
    "                # Often in nuxt.data[0].currentListing or similar\n",
    "                \n",
    "                # Let's dump the keys to see where it might be if we fail\n",
    "                # But for now, let's try to find an object that looks like a listing\n",
    "                \n",
    "                # Helper to search for listing data\n",
    "                def find_listing(data):\n",
    "                    if isinstance(data, dict):\n",
    "                        if \"price\" in data and \"mapLocation\" in data:\n",
    "                            return data\n",
    "                        for k, v in data.items():\n",
    "                            res = find_listing(v)\n",
    "                            if res: return res\n",
    "                    elif isinstance(data, list):\n",
    "                        for item in data:\n",
    "                            res = find_listing(item)\n",
    "                            if res: return res\n",
    "                    return None\n",
    "\n",
    "                listing_data = find_listing(nuxt_data)\n",
    "                \n",
    "                if listing_data:\n",
    "                    details[\"Listing Date\"] = listing_data.get('updatedDate', 'N/A') # or createdDate\n",
    "                    details[\"Price\"] = listing_data.get('price', 'N/A')\n",
    "                    details[\"Area(m2)\"] = listing_data.get('squareMeter', 'N/A') # might be 'sqm'\n",
    "                    if details[\"Area(m2)\"] == 'N/A':\n",
    "                         details[\"Area(m2)\"] = listing_data.get('sqm', 'N/A')\n",
    "\n",
    "                    details[\"Rooms\"] = listing_data.get('roomCount', 'N/A') # might be 'roomAndLivingRoom'\n",
    "                    if details[\"Rooms\"] == 'N/A':\n",
    "                        details[\"Rooms\"] = listing_data.get('roomAndLivingRoom', 'N/A')\n",
    "\n",
    "                    details[\"Bathrooms\"] = listing_data.get('bathroomCount', 'N/A')\n",
    "                    details[\"Building Age\"] = listing_data.get('buildingAge', 'N/A')\n",
    "                    details[\"Furnishment\"] = listing_data.get('furnished', 'N/A') # might be boolean\n",
    "                    details[\"Listing Type\"] = listing_data.get('ownerType', 'N/A')\n",
    "                    \n",
    "                    # Location\n",
    "                    map_loc = listing_data.get('mapLocation', {})\n",
    "                    lat = map_loc.get('lat')\n",
    "                    lon = map_loc.get('lon')\n",
    "                    \n",
    "                    if lat and lon:\n",
    "                        house_coords = (float(lat), float(lon))\n",
    "                        details[\"Distance to Metro (km)\"] = round(geodesic(house_coords, KURTKOY_METRO_COORDS).km, 2)\n",
    "                        details[\"Distance to University (km)\"] = round(geodesic(house_coords, SABANCI_UNIV_COORDS).km, 2)\n",
    "                        details[\"Distance to Bus Station (km)\"] = round(geodesic(house_coords, BUS_STATION_COORDS).km, 2)\n",
    "                    else:\n",
    "                        details[\"Distance to Metro (km)\"] = \"N/A\"\n",
    "                        details[\"Distance to University (km)\"] = \"N/A\"\n",
    "                        details[\"Distance to Bus Station (km)\"] = \"N/A\"\n",
    "                        \n",
    "                    return details\n",
    "        except Exception as e:\n",
    "            print(f\"NUXT extraction failed: {e}\")\n",
    "\n",
    "        # Fallback to CSS\n",
    "        print(\"Falling back to CSS selectors...\")\n",
    "        # ... (Implement CSS fallback if needed, but NUXT is preferred)\n",
    "        \n",
    "        return details\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Error scraping {url}: {e}\")\n",
    "        return None\n",
    "\n",
    "async def main():\n",
    "    async with async_playwright() as p:\n",
    "        browser = await p.chromium.launch(headless=False)\n",
    "        page = await browser.new_page()\n",
    "\n",
    "        print(\"Navigating to Hepsi Emlak...\")\n",
    "        await page.goto(BASE_URL)\n",
    "        \n",
    "        print(\"Waiting for listings...\")\n",
    "        await page.wait_for_selector(\"li.listing-item\", timeout=30000)\n",
    "\n",
    "        # Collect URLs\n",
    "        listings_locator = page.locator(\"li.listing-item a.img-link\")\n",
    "        count = await listings_locator.count()\n",
    "        print(f\"Found {count} potential listings.\")\n",
    "        \n",
    "        listing_urls = set()\n",
    "        for i in range(count):\n",
    "            href = await listings_locator.nth(i).get_attribute(\"href\")\n",
    "            if href:\n",
    "                full_url = f\"https://www.hepsiemlak.com{href}\"\n",
    "                listing_urls.add(full_url)\n",
    "        \n",
    "        print(f\"Collected {len(listing_urls)} unique URLs.\")\n",
    "\n",
    "        all_data = []\n",
    "        for url in listing_urls:\n",
    "            data = await extract_listing_details(page, url)\n",
    "            if data:\n",
    "                all_data.append(data)\n",
    "            await asyncio.sleep(random.uniform(2, 5))\n",
    "\n",
    "        # Export\n",
    "        if all_data:\n",
    "            df = pd.DataFrame(all_data)\n",
    "            output_file = \"hepsiemlak_listings.xlsx\"\n",
    "            df.to_excel(output_file, index=False)\n",
    "            print(f\"Data saved to {output_file}\")\n",
    "            print(df.head())\n",
    "        else:\n",
    "            print(\"No data collected.\")\n",
    "\n",
    "        await browser.close()\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    asyncio.run(main())    "
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
