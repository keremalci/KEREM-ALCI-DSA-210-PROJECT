{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split, cross_val_score, KFold\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_absolute_error, r2_score, mean_squared_error\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.decomposition import PCA\n",
    "import joblib\n",
    "import os\n",
    "\n",
    "# ==========================================\n",
    "# 1. LOAD DATASETS\n",
    "# ==========================================\n",
    "print(\"--- Loading Data ---\")\n",
    "files = {\n",
    "    'Emlakjet': 'data/raw/emlakjet/emlakjet_listings.xlsx',\n",
    "    'Sahibinden': 'data/raw/sahibinden/sahibinden_enriched_listings.xlsx',\n",
    "    'Hepsiemlak': 'data/raw/hepsiemlak/hepsiemlak_listings.xlsx'\n",
    "}\n",
    "\n",
    "dfs = []\n",
    "for source, filename in files.items():\n",
    "    if os.path.exists(filename):\n",
    "        try: \n",
    "            print(f\"Reading {filename}...\")\n",
    "            temp_df = pd.read_excel(filename)\n",
    "            temp_df['Source'] = source\n",
    "            dfs.append(temp_df)\n",
    "        except Exception as e:\n",
    "            print(f\"Failed to read {filename} as Excel: {e}\")\n",
    "            try:\n",
    "                temp_df = pd.read_csv(filename.replace('.xlsx', '.csv'))\n",
    "                temp_df['Source'] = source\n",
    "                dfs.append(temp_df)\n",
    "                print(f\"Read {filename} as CSV instead.\")\n",
    "            except:\n",
    "                pass\n",
    "\n",
    "if not dfs:\n",
    "    raise FileNotFoundError(\"No data files found. Please check the 'data/raw' directory.\")\n",
    "\n",
    "df = pd.concat(dfs, ignore_index=True)\n",
    "print(f\"Total rows loaded: {len(df)}\")\n",
    "\n",
    "# ==========================================\n",
    "# 2. DATA CLEANING & PREPROCESSING\n",
    "# ==========================================\n",
    "print(\"--- Cleaning Data ---\")\n",
    "def clean_price(price):\n",
    "    if pd.isna(price): return np.nan\n",
    "    if isinstance(price, (int, float)): return price\n",
    "    price = str(price).replace('TL', '').replace('.', '').replace(',', '').strip()\n",
    "    try:\n",
    "        return float(price)\n",
    "    except:\n",
    "        return np.nan\n",
    "\n",
    "def clean_numeric(value):\n",
    "    if pd.isna(value): return np.nan\n",
    "    if isinstance(value, (int, float)): return value\n",
    "    value = str(value).replace('m\u00b2', '').replace('m2', '').replace('+1', '').strip()\n",
    "    try:\n",
    "        return float(value.split()[0])\n",
    "    except:\n",
    "        return np.nan\n",
    "\n",
    "if 'Price' in df.columns:\n",
    "    df['clean_price'] = df['Price'].apply(clean_price)\n",
    "elif 'price' in df.columns:\n",
    "    df['clean_price'] = df['price'].apply(clean_price)\n",
    "else:\n",
    "    raise ValueError(\"Could not find a 'Price' or 'price' column.\")\n",
    "\n",
    "df = df.dropna(subset=['clean_price'])\n",
    "\n",
    "# Clean specific numeric features if they exist\n",
    "for col in ['Area(m2)', 'Rooms', 'Building Age']:\n",
    "    if col in df.columns:\n",
    "        df[col] = df[col].apply(clean_numeric)\n",
    "\n",
    "# Clean specific categorical features if they exist\n",
    "for col in ['Furnishment', 'Listing Type']:\n",
    "    if col in df.columns:\n",
    "        df[col] = df[col].fillna('Unknown').astype(str)\n",
    "\n",
    "# Select Features\n",
    "potential_numeric = ['Area(m2)', 'Rooms', 'Building Age']\n",
    "potential_categorical = ['Furnishment', 'Listing Type']\n",
    "\n",
    "numeric_features = [col for col in potential_numeric if col in df.columns]\n",
    "categorical_features = [col for col in potential_categorical if col in df.columns]\n",
    "\n",
    "print(f\"Using Numeric Features: {numeric_features}\")\n",
    "print(f\"Using Categorical Features: {categorical_features}\")\n",
    "\n",
    "X = df[numeric_features + categorical_features]\n",
    "y = df['clean_price']\n",
    "\n",
    "# Pipeline Setup\n",
    "numeric_transformer = Pipeline(steps=[\n",
    "    ('imputer', SimpleImputer(strategy='median')),\n",
    "    ('scaler', StandardScaler())\n",
    "])\n",
    "\n",
    "categorical_transformer = Pipeline(steps=[\n",
    "    ('imputer', SimpleImputer(strategy='constant', fill_value='missing')),\n",
    "    ('onehot', OneHotEncoder(handle_unknown='ignore', sparse_output=False))\n",
    "])\n",
    "\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('num', numeric_transformer, numeric_features),\n",
    "        ('cat', categorical_transformer, categorical_features)\n",
    "    ])\n",
    "\n",
    "# ==========================================\n",
    "# 3. UNSUPERVISED LEARNING (Clustering)\n",
    "# ==========================================\n",
    "print(\"--- Running Unsupervised Learning ---\")\n",
    "try:\n",
    "    X_processed = preprocessor.fit_transform(X)\n",
    "\n",
    "    # PCA (Dimensionality Reduction for Visualization)\n",
    "    n_components = min(2, X_processed.shape[1])\n",
    "    pca = PCA(n_components=n_components)\n",
    "    X_pca = pca.fit_transform(X_processed)\n",
    "\n",
    "    if n_components >= 1: df['PCA1'] = X_pca[:, 0]\n",
    "    if n_components >= 2: df['PCA2'] = X_pca[:, 1]\n",
    "    else: df['PCA2'] = 0\n",
    "\n",
    "    # K-Means (Market Segmentation)\n",
    "    kmeans = KMeans(n_clusters=min(3, len(df)), random_state=42, n_init=10)\n",
    "    df['Cluster'] = kmeans.fit_predict(X_processed)\n",
    "except Exception as e:\n",
    "    print(f\"Skipping Unsupervised Learning: {e}\")\n",
    "\n",
    "# ==========================================\n",
    "# 4. SUPERVISED LEARNING (Training)\n",
    "# ==========================================\n",
    "print(\"--- Running Supervised Learning ---\")\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, shuffle=True)\n",
    "\n",
    "models = {\n",
    "    'Linear Regression': LinearRegression(),\n",
    "    'Decision Tree': DecisionTreeRegressor(random_state=42, max_depth=10),\n",
    "    'Random Forest': RandomForestRegressor(n_estimators=100, random_state=42)\n",
    "}\n",
    "\n",
    "results = {}\n",
    "best_model_score = -np.inf\n",
    "best_model_name = \"\"\n",
    "best_model_obj = None\n",
    "\n",
    "for name, model in models.items():\n",
    "    print(f\"Training {name}...\")\n",
    "    clf = Pipeline(steps=[('preprocessor', preprocessor),\n",
    "                          ('model', model)])\n",
    "    \n",
    "    # Train\n",
    "    clf.fit(X_train, y_train)\n",
    "    y_pred = clf.predict(X_test)\n",
    "    \n",
    "    # Evaluate\n",
    "    mse = mean_squared_error(y_test, y_pred)\n",
    "    rmse = np.sqrt(mse) \n",
    "    mae = mean_absolute_error(y_test, y_pred)\n",
    "    r2 = r2_score(y_test, y_pred) if len(y_test) > 1 else 0.0\n",
    "\n",
    "    results[name] = {'MAE': mae, 'MSE': mse, 'RMSE': rmse, 'R2': r2}\n",
    "    \n",
    "    if r2 > best_model_score:\n",
    "        best_model_score = r2\n",
    "        best_model_name = name\n",
    "        best_model_obj = clf\n",
    "\n",
    "print(f\"Best Model Selected: {best_model_name} (R2: {best_model_score:.4f})\")\n",
    "joblib.dump(best_model_obj, 'final_model.pkl')\n",
    "\n",
    "# Generate Predictions for entire dataset to find deals\n",
    "df['Predicted_Price'] = best_model_obj.predict(X)\n",
    "df['Potential_Savings'] = df['Predicted_Price'] - df['clean_price']\n",
    "\n",
    "# ==========================================\n",
    "# 5. VISUALIZATION (Deal Finder Dashboard)\n",
    "# ==========================================\n",
    "print(\"--- Generating Deal Finder Results Image ---\")\n",
    "plt.style.use('seaborn-v0_8-whitegrid')\n",
    "fig, axes = plt.subplots(1, 3, figsize=(18, 6))\n",
    "fig.suptitle(f'Deal Finder Analysis Results (Best Model: {best_model_name})', fontsize=16)\n",
    "\n",
    "# Plot 1: Model Comparison\n",
    "names = list(results.keys())\n",
    "values = [results[m]['R2'] for m in names]\n",
    "colors = ['green' if n == best_model_name else 'gray' for n in names]\n",
    "axes[0].bar(names, values, color=colors)\n",
    "axes[0].set_title('Model Performance (R\u00b2 Score)')\n",
    "axes[0].set_ylim(0, 1.0)\n",
    "axes[0].set_ylabel('R\u00b2 Score (Higher is Better)')\n",
    "\n",
    "# Plot 2: Clustering (Market Segments)\n",
    "if 'PCA1' in df.columns and 'Cluster' in df.columns:\n",
    "    sns.scatterplot(x='PCA1', y='PCA2', hue='Cluster', data=df, palette='viridis', ax=axes[1], s=100)\n",
    "    axes[1].set_title('Market Segmentation (PCA + K-Means)')\n",
    "    axes[1].set_xlabel('Principal Component 1')\n",
    "    axes[1].set_ylabel('Principal Component 2')\n",
    "\n",
    "# Plot 3: Actual vs Predicted (Deal Spotter)\n",
    "# Deals are points ABOVE the identity line (Predicted > Actual)\n",
    "sns.scatterplot(x='clean_price', y='Predicted_Price', data=df, ax=axes[2], alpha=0.6, label='Listings')\n",
    "min_val = min(df['clean_price'].min(), df['Predicted_Price'].min())\n",
    "max_val = max(df['clean_price'].max(), df['Predicted_Price'].max())\n",
    "axes[2].plot([min_val, max_val], [min_val, max_val], 'r--', label='Fair Value (x=y)')\n",
    "\n",
    "# Highlight Deals (Top 50 savings)\n",
    "deals = df.nlargest(50, 'Potential_Savings')\n",
    "axes[2].scatter(deals['clean_price'], deals['Predicted_Price'], color='green', s=50, label='Best Deals')\n",
    "\n",
    "axes[2].set_title('Deal Finder: Actual vs. Predicted Price')\n",
    "axes[2].set_xlabel('Actual Price (TL)')\n",
    "axes[2].set_ylabel('Predicted Fair Price (TL)')\n",
    "axes[2].legend()\n",
    "\n",
    "plt.tight_layout(rect=[0, 0.03, 1, 0.95])\n",
    "plt.savefig('data/outputs/deal_finder_results.png', dpi=300)\n",
    "print(\"Saved visualization to 'data/outputs/deal_finder_results.png'\")\n",
    "\n",
    "# ==========================================\n",
    "# 5b. ADDITIONAL VISUALIZATION (Distance Analysis)\n",
    "# ==========================================\n",
    "print(\"--- Generating Distance Analysis Image ---\")\n",
    "# Create additional visualization for distance analysis\n",
    "fig2, axes2 = plt.subplots(1, 3, figsize=(18, 5))\n",
    "\n",
    "# Distance correlations\n",
    "if 'Distance to Metro (km)' in df.columns:\n",
    "    # Clean distance column if needed (it might be string with 'km' or something, though load_all_data in analyze_data didn't seem to do much beyond basic cleaning. \n",
    "    # analyze_data.py didn't have specific cleaning for this, assuming it was numeric/clean enough or handled by pandas read_excel if numeric.\n",
    "    # However, let's ensure it's numeric.\n",
    "    pass \n",
    "\n",
    "has_plots = False\n",
    "\n",
    "if 'Distance to Metro (km)' in df.columns:\n",
    "    # Simple cleaning just in case\n",
    "    df['Distance to Metro (km)'] = pd.to_numeric(df['Distance to Metro (km)'], errors='coerce')\n",
    "    axes2[0].scatter(df['Distance to Metro (km)'], df['clean_price'], alpha=0.6, color='blue')\n",
    "    axes2[0].set_title('Price vs Distance to Metro', fontsize=12, fontweight='bold')\n",
    "    axes2[0].set_xlabel('Distance to Metro (km)')\n",
    "    axes2[0].set_ylabel('Price (\u20ba)')\n",
    "    has_plots = True\n",
    "\n",
    "if 'Distance to University (km)' in df.columns:\n",
    "    df['Distance to University (km)'] = pd.to_numeric(df['Distance to University (km)'], errors='coerce')\n",
    "    axes2[1].scatter(df['Distance to University (km)'], df['clean_price'], alpha=0.6, color='green')\n",
    "    axes2[1].set_title('Price vs Distance to University', fontsize=12, fontweight='bold')\n",
    "    axes2[1].set_xlabel('Distance to University (km)')\n",
    "    axes2[1].set_ylabel('Price (\u20ba)')\n",
    "    has_plots = True\n",
    "\n",
    "if 'Building Age' in df.columns:\n",
    "    # Building Age is already cleaned in previous steps to be numeric\n",
    "    axes2[2].scatter(df['Building Age'], df['clean_price'], alpha=0.6, color='orange')\n",
    "    axes2[2].set_title('Price vs Building Age', fontsize=12, fontweight='bold')\n",
    "    axes2[2].set_xlabel('Building Age (years)')\n",
    "    axes2[2].set_ylabel('Price (\u20ba)')\n",
    "    has_plots = True\n",
    "\n",
    "if has_plots:\n",
    "    os.makedirs('visualizations', exist_ok=True)\n",
    "    plt.tight_layout()\n",
    "    plt.savefig('visualizations/distance_analysis.png', dpi=300, bbox_inches='tight')\n",
    "    print(\"Saved visualization to 'visualizations/distance_analysis.png'\")\n",
    "\n",
    "# ==========================================\n",
    "# 6. EFFICIENT EXCEL ORGANIZATION\n",
    "# ==========================================\n",
    "print(\"--- Saving Organized Excel File ---\")\n",
    "results_df = pd.DataFrame(results).T.reset_index().rename(columns={'index': 'Model'})\n",
    "\n",
    "# Sort deals by highest savings first\n",
    "best_deals_df = df[df['Potential_Savings'] > 0].sort_values(by='Potential_Savings', ascending=False)\n",
    "best_deals_df = best_deals_df[['clean_price', 'Predicted_Price', 'Potential_Savings', 'Cluster'] + [col for col in df.columns if 'URL' in col or col == 'Source']]\n",
    "\n",
    "with pd.ExcelWriter('data/outputs/ml_analysis_results.xlsx') as writer:\n",
    "    # Sheet 1: Model Summary (High Level)\n",
    "    results_df.to_excel(writer, sheet_name='1_Model_Performance', index=False)\n",
    "    \n",
    "    # Sheet 2: Actionable Insights (The Deals)\n",
    "    best_deals_df.to_excel(writer, sheet_name='2_Best_Deals_Finder', index=False)\n",
    "    \n",
    "    # Sheet 3: Deep Dive (Clustering Data)\n",
    "    cluster_cols = ['clean_price', 'Cluster', 'PCA1', 'PCA2']\n",
    "    df[cluster_cols].to_excel(writer, sheet_name='3_Clustering_Analysis', index=False)\n",
    "\n",
    "print(\"Saved organized results to 'data/outputs/ml_analysis_results.xlsx'\")\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"ML ANALYSIS COMPLETE\")\n",
    "print(\"=\"*60)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}